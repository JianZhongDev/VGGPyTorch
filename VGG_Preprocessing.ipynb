{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ee2727-bd87-4116-a365-7f834d8bb305",
   "metadata": {},
   "source": [
    "# VGG_Preprocessing\n",
    "DESCRIPTION: This notebook includes data preprocessing scripts for VGG model training\n",
    "\n",
    "@author: Jian Zhong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221d1cf-8e05-4ee5-abd3-e4ad5e97be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## include modules \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e85c6c-dd6b-4e50-9b83-d72cd4ae0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data set\n",
    "\n",
    "## convert image into torch.tensor\n",
    "data_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32,scale = True),\n",
    "])\n",
    "\n",
    "## NOTE: The dataset_root_dir would need to be changed according to the desired data location in your computer    \n",
    "dataset_root_dir = r\"E:\\Python\\DataSet\\TorchDataSet\\CIFAR10\"\n",
    "\n",
    "## create training data set\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root = dataset_root_dir,\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "## create test data set\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root = dataset_root_dir,\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "print(f\"train_data length: {len(train_data)}\")\n",
    "print(f\"test_data lenght: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36070a8d-5c90-46f8-a278-bdf729e5d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data loader\n",
    "\n",
    "train_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, \n",
    "                                               batch_size = train_batch_size, \n",
    "                                               shuffle = False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, \n",
    "                                              batch_size = test_batch_size, \n",
    "                                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5d3f8-6b7a-4b54-8620-2b457939422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculated the averaged channel values across the entire data set\n",
    "\n",
    "input_dataloader = train_dataloader\n",
    "nof_batchs = len(input_dataloader)\n",
    "avg_ch_vals = [None for _ in range(nof_batchs)]\n",
    "\n",
    "for i_batch, data in enumerate(input_dataloader):\n",
    "    inputs, labels = data\n",
    "    cur_avg_ch = torch.mean(inputs, dim = (-1,-2), keepdim = True)\n",
    "    avg_ch_vals[i_batch] = cur_avg_ch\n",
    "\n",
    "avg_ch_vals = torch.cat(avg_ch_vals, dim = 0)\n",
    "avg_ch_val = torch.mean(avg_ch_vals, dim = 0, keepdim = False)\n",
    "\n",
    "print(\"result size = \")\n",
    "print(avg_ch_val.size())\n",
    "print(\"result val = \")\n",
    "print(repr(avg_ch_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5719b0d-fe84-4c90-8dcb-4660a73f7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVD decomposition for covariance matrix of image channels across all the pixels \n",
    "\n",
    "input_dataloader = train_dataloader\n",
    "nof_batchs = len(input_dataloader)\n",
    "ch_vecs = [None for _ in range(nof_batchs)]\n",
    "\n",
    "for i_batch, data in enumerate(input_dataloader):\n",
    "    inputs, labels = data\n",
    "    # swap channel and batch axis and flatten the dimension of (batch, image height, image width)\n",
    "    ch_vecs[i_batch] = torch.flatten(torch.swapaxes(inputs, 0, 1), start_dim = 1, end_dim = -1)\n",
    "\n",
    "ch_vecs = torch.cat(ch_vecs, dim = -1)\n",
    "ch_cov = torch.cov(ch_vecs)\n",
    "ch_vecs = None\n",
    "\n",
    "U, S, Vh = torch.linalg.svd(ch_cov, full_matrices = True)\n",
    "\n",
    "## Each column of U is a channel PCA eigenvector\n",
    "## S contains the corresponding to eigenvectors\n",
    "\n",
    "print(\"U:\")\n",
    "print(repr(U))\n",
    "print(\"S:\")\n",
    "print(S)\n",
    "print(\"Vh:\")\n",
    "print(Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270c658-6b87-4589-9c8f-ee7f19862730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
